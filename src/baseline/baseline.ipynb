{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\", pad_token = \"<pad>\")\n",
    "model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'pair_id', 'id1', 'id2', 'text1', 'text2', 'overall',\n",
      "       'lang1', 'lang2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../../data/train/train.csv\")\n",
    "test_data = pd.read_csv(\"../../data/test/final_test_pairs.csv\")\n",
    "\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpad_embedding\u001b[39m(text: \u001b[43mTensor\u001b[49m, target_length: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Pad the input text with ones to reach the target length of a sequence (sentence).\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m        Tensor: The padded text tensor.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     text \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tensor' is not defined"
     ]
    }
   ],
   "source": [
    "def pad_embedding(text: Tensor, target_length: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Pad the input text with ones to reach the target length of a sequence (sentence).\n",
    "    \n",
    "    Args:\n",
    "        text (Tensor): The input text tensor.\n",
    "        target_length (int): The desired length of the padded text tensor.\n",
    "        \n",
    "    Returns:\n",
    "        Tensor: The padded text tensor.\n",
    "    \"\"\"\n",
    "    text = torch.tensor(text)\n",
    "\n",
    "    # add ones to the end of the text (1 is the padding token)\n",
    "    text = torch.nn.functional.pad(text, (0, target_length - text.shape[1]), 'constant', 1)\n",
    "\n",
    "    return text\n",
    "\n",
    "def tokenize_and_shorten_sentence(text: str) -> Tensor:\n",
    "    \"\"\"\n",
    "    Tokenize the input text and shorten it to 256 tokens.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: The tokenized and shortened text tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_text = tokenizer(text, return_tensors=\"pt\", padding=False, truncation=False) #padding = False and truncation = False to get the exact length of the text\n",
    "    if tokenized_text[\"input_ids\"].shape[1] > 256:\n",
    "        # TODO: decide where to truncate the text, meaning how many tokens to keep from the head and how many from the tail\n",
    "        # note: the model has a max length of 512 tokens and we need to keep the [CLS] ? and [SEP] tokens\n",
    "        tokenized_text[\"shorten_ids\"] = torch.cat((tokenized_text[\"input_ids\"][:, :200], tokenized_text[\"input_ids\"][:, -55:]), dim=1)\n",
    "    else:\n",
    "        tokenized_text[\"shorten_ids\"] = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=False, max_length=256)[\"input_ids\"]\n",
    "        \n",
    "    return tokenized_text[\"shorten_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/wd7qc7cs1wd8pr3h4y_6lxxw0000gn/T/ipykernel_1203/2397932662.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text = torch.tensor(text)\n"
     ]
    }
   ],
   "source": [
    "NUM = 1 #len(train_data)\n",
    "#train_embeddings = torch.empty((NUM, 512, 768))\n",
    "train_embeddings = torch.empty((NUM, 768)) # note: take into account the [CLS] token only as it represents the whole sentence\n",
    "\n",
    "sep_token = torch.tensor([tokenizer.sep_token_id]).unsqueeze(0)\n",
    "\n",
    "for i in range(len(train_data[:NUM])):\n",
    "    text1 = train_data[\"text1\"][i]\n",
    "    text2 = train_data[\"text2\"][i]\n",
    "    text1_tokenized = tokenize_and_shorten_sentence(text1)\n",
    "    text2_tokenized = tokenize_and_shorten_sentence(text2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text = torch.cat((text1_tokenized, sep_token, text2_tokenized), dim=1)\n",
    "        # TODO: investigate the attention mask\n",
    "        text = {\"input_ids\": text, \"attention_mask\": torch.ones(text.shape)}\n",
    "        outputs = model(**text)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "        embeddings = pad_embedding(embeddings, 512)\n",
    "\n",
    "        cls_token_embedding = outputs.pooler_output\n",
    "        train_embeddings[i] = cls_token_embedding\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
