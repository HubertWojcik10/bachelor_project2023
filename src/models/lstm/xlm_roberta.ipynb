{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/germa/anaconda3/envs/project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/c6/k78nzngn7nbdd0786bxl3s0c0000gn/T/ipykernel_7599/1105922383.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/Users/germa/thesis/bachelor_project2023/src/utils')\n",
    "from chunker import Chunker\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import List, Tuple\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRoberta(nn.Module):\n",
    "    def __init__(self, model_name: str):\n",
    "        super(XLMRoberta, self).__init__()\n",
    "        self.model = XLMRobertaModel.from_pretrained(model_name)\n",
    "        self.tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "        self.chunker = Chunker(self.tokenizer, 512)\n",
    "        self.train_df = self.get_data('../../../data/train/train.csv')\n",
    "    \n",
    "    def get_data(self, path):\n",
    "        train_df = pd.read_csv(path)\n",
    "        train_short_df = train_df.head(3)\n",
    "        return train_short_df\n",
    "    \n",
    "    def chunk_data(self, df ,col1 = \"text1\", col2 = \"text2\"):\n",
    "        texts1, texts2 = df[col1], df[col2]\n",
    "        input_ids = []\n",
    "        for i in range(len(texts1)):\n",
    "            input_id_1 = self.chunker.chunk(texts1[i])\n",
    "            input_id_2 = self.chunker.chunk(texts2[i])\n",
    "            input_ids.append([input_id_1, input_id_2])\n",
    "            \n",
    "        return input_ids\n",
    "\n",
    "    def chunked_data(self):\n",
    "        input_ids = self.chunk_data(self.train_df)\n",
    "        return input_ids\n",
    "    \n",
    "    def run(self):\n",
    "        input_ids = self.chunked_data()\n",
    "        output = []\n",
    "        for i in range(len(input_ids)):\n",
    "            row_emb = []\n",
    "            for text in input_ids[i]:\n",
    "                chunks_emb = []\n",
    "                for chunk in text:\n",
    "                    input_ids = torch.tensor(chunk).unsqueeze(0)\n",
    "                    attention_mask = [1 if i != 0 else 0 for i in input_ids.tolist()]\n",
    "                    attention_mask = torch.tensor(attention_mask).unsqueeze(0)\n",
    "                    outputs= self.model(input_ids, attention_mask)\n",
    "                    last_hidden_state = outputs.last_hidden_state.mean(dim=1)\n",
    "                    chunks_emb.append([last_hidden_state])\n",
    "                row_emb.append([chunks_emb])\n",
    "            output.append(row_emb)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob = XLMRoberta(\"xlm-roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[71], line 33\u001b[0m, in \u001b[0;36mXLMRoberta.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_ids)):\n\u001b[1;32m     32\u001b[0m     row_emb \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     34\u001b[0m         chunks_emb \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m text:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "rob.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
