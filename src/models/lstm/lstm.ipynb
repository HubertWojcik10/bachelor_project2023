{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import List, Tuple\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import sys\n",
    "sys.path.append('/Users/germa/thesis/bachelor_project2023/src/models/lstm')\n",
    "from xlm_roberta import XLMRoberta\n",
    "sys.path.append('/Users/germa/thesis/bachelor_project2023/src/utils')\n",
    "from chunker import Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMOnXLMRoberta(nn.Module):\n",
    "    def __init__(self, input_size, lstm_hidden_size, num_lstm_layers, model_name = 'xlm-roberta-base', train_path = '../../../data/train/train.csv', train_size = 0.8, batch_size = 32, shuffle = True):\n",
    "        super(LSTMOnXLMRoberta, self).__init__()\n",
    "        self.xlmroberta_model = XLMRoberta(model_name)\n",
    "        self.tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "        self.chunker = Chunker(self.tokenizer, 512)\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=num_lstm_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=False)\n",
    "        self.fc = nn.Linear(lstm_hidden_size * 2, 1)\n",
    "\n",
    "        parameters_to_optimize = list(self.fc.parameters()) + list(self.lstm.parameters()) + list(self.xlmroberta_model.parameters())\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(parameters_to_optimize, lr=1e-5)\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.train_df= self.get_data(train_path)\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "    def parameter_to_optimize(self):\n",
    "        for param in self.xlmroberta_model.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.lstm.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def get_data(self, path):\n",
    "        train_df = pd.read_csv(path)\n",
    "        train_short_df = train_df.head(200)\n",
    "        return train_short_df\n",
    "    \n",
    "    def chunk_data(self, df):\n",
    "        texts1, texts2, labels = df[\"text1\"], df[\"text2\"], df[\"overall\"]\n",
    "        input_ids = []\n",
    "        for i in range(len(texts1)):\n",
    "            input_id_1 = self.chunker.chunk(texts1[i])\n",
    "            input_id_2 = self.chunker.chunk(texts2[i])\n",
    "            input_ids.append([input_id_1, input_id_2])           \n",
    "        return input_ids, labels\n",
    "    \n",
    "        \n",
    "    def _manage_device(self) -> None:\n",
    "        \"\"\"\n",
    "            Manage the device to run the model on\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.xlmroberta_model.to(self.device)\n",
    "        self.lstm.to(self.device)\n",
    "        self.fc.to(self.device)\n",
    "    \n",
    "    def get_embeddings(self, input_ids):\n",
    "        \"\"\"\n",
    "            Get the embeddings from the XLM-Roberta model\n",
    "        \"\"\"\n",
    "        outputs = self.xlmroberta_model.run(input_ids)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def pad_to_same_size(self, tensors):\n",
    "        max_size = max(tensor.size(0) for tensor in tensors)\n",
    "        padded_tensors = []\n",
    "        for tensor in tensors:\n",
    "            if tensor.size(0) < max_size:\n",
    "                padding = torch.zeros(max_size - tensor.size(0), tensor.size(1))\n",
    "                padded_tensor = torch.cat((tensor, padding), dim=0)\n",
    "                padded_tensors.append(padded_tensor)\n",
    "            else:\n",
    "                padded_tensors.append(tensor)\n",
    "        return torch.stack(padded_tensors)\n",
    "    \n",
    "    def pearson_correlation(self, labels_val, output_val):\n",
    "        print(f\"Labels: {labels_val}\")\n",
    "        print(f\"Predictions: {output_val}\")\n",
    "\n",
    "        output_val= np.array([t.item() for t in output_val])\n",
    "        return np.corrcoef(labels_val, output_val)[0][1]\n",
    "\n",
    "    \n",
    "    def evaluate_model(self, input_ids_val, labels_val, batch_size = 4):\n",
    "        \"\"\"\n",
    "            Evaluate the model \"\"\" \n",
    "        self.eval()\n",
    "        output_val = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(input_ids_val), batch_size):\n",
    "                input_batch_data = input_ids_val[i:i + batch_size]\n",
    "                input_batch = self.get_embeddings(input_batch_data)\n",
    "                label_batch = labels_val[i:i + batch_size]\n",
    "\n",
    "                for row, label in zip(input_batch, label_batch):\n",
    "                    index1, index2 = len(row[0]), len(row[1])\n",
    "                    row_padded = self.pad_to_same_size(row) \n",
    "                    lstm_out, _ = self.lstm(row_padded)\n",
    "                    lstm_out_last1 = lstm_out[0, index1 - 1, :]\n",
    "                    lstm_out_last2 = lstm_out[1, index2 - 1, :]\n",
    "                    nn = torch.cat((lstm_out_last1, lstm_out_last2), 0)\n",
    "                    output = self.fc(nn)\n",
    "                    output_val.append(output)\n",
    "                    \n",
    "        pearson = self.pearson_correlation(labels_val, output_val)\n",
    "        return pearson\n",
    "    \n",
    "    def train_model(self, input_ids_train, labels_train, input_ids_val, labels_val, batch_size = 4):\n",
    "        \"\"\"\n",
    "            Train the model\n",
    "        \"\"\"\n",
    "        best_pearson = -1\n",
    "        self.train()\n",
    "        for epoch in range(5):\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "\n",
    "            for i in range(0, len(input_ids_train), batch_size):\n",
    "                print(f\"Batch: {i/batch_size}\")\n",
    "                input_batch_data = input_ids_train[i:i + batch_size]\n",
    "                input_batch = self.get_embeddings(input_batch_data)\n",
    "                label_batch = labels_train[i:i + batch_size]\n",
    "                batch_loss = 0\n",
    "                self.optimizer.zero_grad()  # Clear gradients\n",
    "                outputs = []\n",
    "                for row, label in zip(input_batch, label_batch):\n",
    "                    index1, index2 = len(row[0]), len(row[1])\n",
    "                    row_padded = self.pad_to_same_size(row) \n",
    "                    lstm_out, _ = self.lstm(row_padded)\n",
    "                    lstm_out_last1 = lstm_out[0, index1 - 1, :]\n",
    "                    lstm_out_last2 = lstm_out[1, index2 - 1, :]\n",
    "                    nn = torch.cat((lstm_out_last1, lstm_out_last2), 0)\n",
    "                    output = self.fc(nn)\n",
    "                    outputs.append(output)\n",
    "                    loss = self.loss_function(output, torch.tensor(label, dtype=torch.float32).view(1))\n",
    "                    batch_loss = batch_loss + loss\n",
    "\n",
    "                batch_loss = batch_loss/batch_size \n",
    "                batch_loss.backward()  # Backpropagation \n",
    "                torch.nn.utils.clip_grad_norm_(self.parameters(), 1.0)\n",
    "                self.optimizer.step()  # Update weights\n",
    "                print(f\"Batch loss: {batch_loss}\")\n",
    "                batch_pearson = self.pearson_correlation(label_batch, outputs)\n",
    "                print(f\"Batch pearson: {batch_pearson}\")\n",
    "        \n",
    "            eval_pearson = self.evaluate_model(input_ids_val, labels_val)\n",
    "            print(f\"Eval pearson: {eval_pearson}\")\n",
    "            if eval_pearson > best_pearson:\n",
    "                best_pearson = eval_pearson\n",
    "                print(\"Saving the model...\")\n",
    "                torch.save(self.state_dict(), \"../../../saved_models/xlmroberta_on_lstm/best_lstm.pth\")\n",
    "\n",
    "    def run(self):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        self._manage_device()\n",
    "        #shuffle data\n",
    "        train_df = self.train_df.sample(frac=1).reset_index(drop=True)\n",
    "        train_df, val_df = train_df[:int(len(train_df) * 0.8)], train_df[int(len(train_df) * 0.8):].reset_index(drop=True)\n",
    "        input_ids_train, labels_train = self.chunk_data(train_df)\n",
    "        input_ids_val, labels_val = self.chunk_data(val_df)\n",
    "        self.parameter_to_optimize()\n",
    "        self.train_model(input_ids_train, labels_train, input_ids_val, labels_val)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2221 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Batch: 0.0\n",
      "Batch loss: 11.895381927490234\n",
      "Labels: 0    3.666667\n",
      "1    3.666667\n",
      "2    2.000000\n",
      "3    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([-0.0482], grad_fn=<ViewBackward0>), tensor([-0.0185], grad_fn=<ViewBackward0>), tensor([0.0155], grad_fn=<ViewBackward0>), tensor([-0.0327], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.8794361434125155\n",
      "Batch: 1.0\n",
      "Batch loss: 14.183785438537598\n",
      "Labels: 4    4.0\n",
      "5    3.0\n",
      "6    4.0\n",
      "7    4.0\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([-0.0045], grad_fn=<ViewBackward0>), tensor([0.0285], grad_fn=<ViewBackward0>), tensor([0.0069], grad_fn=<ViewBackward0>), tensor([0.0094], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.8962818683359116\n",
      "Batch: 2.0\n",
      "Batch loss: 5.088973045349121\n",
      "Labels: 8     3.000000\n",
      "9     1.000000\n",
      "10    2.333333\n",
      "11    2.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.0360], grad_fn=<ViewBackward0>), tensor([0.0356], grad_fn=<ViewBackward0>), tensor([0.0495], grad_fn=<ViewBackward0>), tensor([0.0042], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.05240199709080054\n",
      "Batch: 3.0\n",
      "Batch loss: 8.486334800720215\n",
      "Labels: 12    4.000000\n",
      "13    3.333333\n",
      "14    1.000000\n",
      "15    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.0356], grad_fn=<ViewBackward0>), tensor([0.0978], grad_fn=<ViewBackward0>), tensor([0.0577], grad_fn=<ViewBackward0>), tensor([0.0452], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.030485969753201083\n",
      "Batch: 4.0\n",
      "Batch loss: 9.784859657287598\n",
      "Labels: 16    1.666667\n",
      "17    4.000000\n",
      "18    3.666667\n",
      "19    3.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.1003], grad_fn=<ViewBackward0>), tensor([0.0823], grad_fn=<ViewBackward0>), tensor([0.1084], grad_fn=<ViewBackward0>), tensor([0.0544], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.10764082954153081\n",
      "Batch: 5.0\n",
      "Batch loss: 9.095258712768555\n",
      "Labels: 20    3.666667\n",
      "21    4.000000\n",
      "22    2.666667\n",
      "23    1.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.0823], grad_fn=<ViewBackward0>), tensor([0.1009], grad_fn=<ViewBackward0>), tensor([0.0718], grad_fn=<ViewBackward0>), tensor([0.0698], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.8326341778647302\n",
      "Batch: 6.0\n",
      "Batch loss: 8.504522323608398\n",
      "Labels: 24    4.000000\n",
      "25    1.333333\n",
      "26    1.666667\n",
      "27    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.1226], grad_fn=<ViewBackward0>), tensor([0.1224], grad_fn=<ViewBackward0>), tensor([0.1031], grad_fn=<ViewBackward0>), tensor([0.1176], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.37725888790921147\n",
      "Batch: 7.0\n",
      "Batch loss: 9.485162734985352\n",
      "Labels: 28    3.333333\n",
      "29    1.666667\n",
      "30    3.333333\n",
      "31    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.1038], grad_fn=<ViewBackward0>), tensor([0.1153], grad_fn=<ViewBackward0>), tensor([0.1173], grad_fn=<ViewBackward0>), tensor([0.1580], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.5192773568547924\n",
      "Batch: 8.0\n",
      "Batch loss: 8.965004920959473\n",
      "Labels: 32    1.333333\n",
      "33    4.000000\n",
      "34    2.333333\n",
      "35    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.1833], grad_fn=<ViewBackward0>), tensor([0.1494], grad_fn=<ViewBackward0>), tensor([0.1870], grad_fn=<ViewBackward0>), tensor([0.1137], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.8459384525059671\n",
      "Batch: 9.0\n",
      "Batch loss: 10.773326873779297\n",
      "Labels: 36    3.333333\n",
      "37    2.200000\n",
      "38    4.000000\n",
      "39    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.2222], grad_fn=<ViewBackward0>), tensor([0.1730], grad_fn=<ViewBackward0>), tensor([0.2170], grad_fn=<ViewBackward0>), tensor([0.1277], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.029393400717492323\n",
      "Batch: 10.0\n",
      "Batch loss: 9.100781440734863\n",
      "Labels: 40    3.333333\n",
      "41    3.666667\n",
      "42    3.333333\n",
      "43    2.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.1936], grad_fn=<ViewBackward0>), tensor([0.1974], grad_fn=<ViewBackward0>), tensor([0.1585], grad_fn=<ViewBackward0>), tensor([0.2287], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.6676174630205768\n",
      "Batch: 11.0\n",
      "Batch loss: 7.701024532318115\n",
      "Labels: 44    3.333333\n",
      "45    4.000000\n",
      "46    1.000000\n",
      "47    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.2600], grad_fn=<ViewBackward0>), tensor([0.1795], grad_fn=<ViewBackward0>), tensor([0.1678], grad_fn=<ViewBackward0>), tensor([0.2030], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.4135658917195166\n",
      "Batch: 12.0\n",
      "Batch loss: 11.419868469238281\n",
      "Labels: 48    4.000000\n",
      "49    3.666667\n",
      "50    3.000000\n",
      "51    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.2943], grad_fn=<ViewBackward0>), tensor([0.2018], grad_fn=<ViewBackward0>), tensor([0.3569], grad_fn=<ViewBackward0>), tensor([0.4006], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.051610568307288496\n",
      "Batch: 13.0\n",
      "Batch loss: 7.0358428955078125\n",
      "Labels: 52    2.333333\n",
      "53    4.000000\n",
      "54    1.666667\n",
      "55    3.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.2549], grad_fn=<ViewBackward0>), tensor([0.2878], grad_fn=<ViewBackward0>), tensor([0.4453], grad_fn=<ViewBackward0>), tensor([0.4091], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.37258546394361425\n",
      "Batch: 14.0\n",
      "Batch loss: 13.135550498962402\n",
      "Labels: 56    4.000000\n",
      "57    3.666667\n",
      "58    4.000000\n",
      "59    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.2355], grad_fn=<ViewBackward0>), tensor([0.2804], grad_fn=<ViewBackward0>), tensor([0.3642], grad_fn=<ViewBackward0>), tensor([0.3007], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.18446784721650392\n",
      "Batch: 15.0\n",
      "Batch loss: 10.277708053588867\n",
      "Labels: 60    4.000000\n",
      "61    2.333333\n",
      "62    3.666667\n",
      "63    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.3736], grad_fn=<ViewBackward0>), tensor([0.3892], grad_fn=<ViewBackward0>), tensor([0.3355], grad_fn=<ViewBackward0>), tensor([0.3829], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.34740418666961237\n",
      "Batch: 16.0\n",
      "Batch loss: 12.280207633972168\n",
      "Labels: 64    4.000000\n",
      "65    4.000000\n",
      "66    3.666667\n",
      "67    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.3545], grad_fn=<ViewBackward0>), tensor([0.4465], grad_fn=<ViewBackward0>), tensor([0.5125], grad_fn=<ViewBackward0>), tensor([0.3592], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.829599814706169\n",
      "Batch: 17.0\n",
      "Batch loss: 1.2130852937698364\n",
      "Labels: 68    2.333333\n",
      "69    1.000000\n",
      "70    1.000000\n",
      "71    1.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.3688], grad_fn=<ViewBackward0>), tensor([0.3260], grad_fn=<ViewBackward0>), tensor([0.4687], grad_fn=<ViewBackward0>), tensor([0.4938], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.38014890798487627\n",
      "Batch: 18.0\n",
      "Batch loss: 4.426048755645752\n",
      "Labels: 72    4.000000\n",
      "73    1.000000\n",
      "74    1.333333\n",
      "75    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.4615], grad_fn=<ViewBackward0>), tensor([0.6299], grad_fn=<ViewBackward0>), tensor([0.4539], grad_fn=<ViewBackward0>), tensor([0.5995], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.3878231484859814\n",
      "Batch: 19.0\n",
      "Batch loss: 8.208653450012207\n",
      "Labels: 76    3.000000\n",
      "77    4.000000\n",
      "78    3.333333\n",
      "79    2.750000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.4485], grad_fn=<ViewBackward0>), tensor([0.4141], grad_fn=<ViewBackward0>), tensor([0.4336], grad_fn=<ViewBackward0>), tensor([0.5013], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.8811272756283308\n",
      "Batch: 20.0\n",
      "Batch loss: 8.057452201843262\n",
      "Labels: 80    3.500000\n",
      "81    4.000000\n",
      "82    3.666667\n",
      "83    2.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.4638], grad_fn=<ViewBackward0>), tensor([0.5470], grad_fn=<ViewBackward0>), tensor([0.5958], grad_fn=<ViewBackward0>), tensor([0.7125], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.7705798616096504\n",
      "Batch: 21.0\n",
      "Batch loss: 4.076902866363525\n",
      "Labels: 84    3.666667\n",
      "85    1.000000\n",
      "86    3.333333\n",
      "87    1.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.7593], grad_fn=<ViewBackward0>), tensor([0.5298], grad_fn=<ViewBackward0>), tensor([0.5744], grad_fn=<ViewBackward0>), tensor([0.8520], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.044452306437358806\n",
      "Batch: 22.0\n",
      "Batch loss: 5.762374401092529\n",
      "Labels: 88    4.000000\n",
      "89    1.333333\n",
      "90    4.000000\n",
      "91    2.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.6831], grad_fn=<ViewBackward0>), tensor([0.9135], grad_fn=<ViewBackward0>), tensor([0.7605], grad_fn=<ViewBackward0>), tensor([0.8265], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.9288082709939645\n",
      "Batch: 23.0\n",
      "Batch loss: 4.858851432800293\n",
      "Labels: 92    1.333333\n",
      "93    1.333333\n",
      "94    4.000000\n",
      "95    3.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.7478], grad_fn=<ViewBackward0>), tensor([0.7226], grad_fn=<ViewBackward0>), tensor([0.9169], grad_fn=<ViewBackward0>), tensor([0.6312], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.27916597487094386\n",
      "Batch: 24.0\n",
      "Batch loss: 3.0670223236083984\n",
      "Labels: 96    1.333333\n",
      "97    4.000000\n",
      "98    2.500000\n",
      "99    1.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.1107], grad_fn=<ViewBackward0>), tensor([0.9948], grad_fn=<ViewBackward0>), tensor([0.7304], grad_fn=<ViewBackward0>), tensor([0.7634], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.1355129825759123\n",
      "Batch: 25.0\n",
      "Batch loss: 3.718502998352051\n",
      "Labels: 100    1.400000\n",
      "101    3.000000\n",
      "102    4.000000\n",
      "103    1.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.9773], grad_fn=<ViewBackward0>), tensor([0.9820], grad_fn=<ViewBackward0>), tensor([0.7763], grad_fn=<ViewBackward0>), tensor([0.8525], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.44750094401897444\n",
      "Batch: 26.0\n",
      "Batch loss: 5.307704448699951\n",
      "Labels: 104    4.000000\n",
      "105    4.000000\n",
      "106    3.000000\n",
      "107    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.2610], grad_fn=<ViewBackward0>), tensor([1.3183], grad_fn=<ViewBackward0>), tensor([1.0365], grad_fn=<ViewBackward0>), tensor([1.0291], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.9720261528930882\n",
      "Batch: 27.0\n",
      "Batch loss: 7.598197937011719\n",
      "Labels: 108    3.333333\n",
      "109    4.000000\n",
      "110    4.000000\n",
      "111    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.9215], grad_fn=<ViewBackward0>), tensor([1.1499], grad_fn=<ViewBackward0>), tensor([1.1294], grad_fn=<ViewBackward0>), tensor([1.1342], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.9967519012796834\n",
      "Batch: 28.0\n",
      "Batch loss: 5.326995849609375\n",
      "Labels: 112    4.000000\n",
      "113    4.000000\n",
      "114    1.333333\n",
      "115    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.5645], grad_fn=<ViewBackward0>), tensor([0.8975], grad_fn=<ViewBackward0>), tensor([1.1853], grad_fn=<ViewBackward0>), tensor([1.6065], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.25443407239159627\n",
      "Batch: 29.0\n",
      "Batch loss: 7.847014427185059\n",
      "Labels: 116    4.000000\n",
      "117    4.000000\n",
      "118    3.666667\n",
      "119    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([0.8866], grad_fn=<ViewBackward0>), tensor([1.2494], grad_fn=<ViewBackward0>), tensor([1.4457], grad_fn=<ViewBackward0>), tensor([0.9675], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.7975934957940384\n",
      "Batch: 30.0\n",
      "Batch loss: 1.9331358671188354\n",
      "Labels: 120    2.000000\n",
      "121    1.666667\n",
      "122    2.333333\n",
      "123    3.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.4653], grad_fn=<ViewBackward0>), tensor([1.8671], grad_fn=<ViewBackward0>), tensor([1.0675], grad_fn=<ViewBackward0>), tensor([1.2575], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.5857131893850892\n",
      "Batch: 31.0\n",
      "Batch loss: 2.6269748210906982\n",
      "Labels: 124    3.000000\n",
      "125    1.000000\n",
      "126    3.333333\n",
      "127    3.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.1322], grad_fn=<ViewBackward0>), tensor([1.3410], grad_fn=<ViewBackward0>), tensor([1.7055], grad_fn=<ViewBackward0>), tensor([1.6043], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.43101245316720194\n",
      "Batch: 32.0\n",
      "Batch loss: 2.395242214202881\n",
      "Labels: 128    2.333333\n",
      "129    2.000000\n",
      "130    3.333333\n",
      "131    3.500000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.3453], grad_fn=<ViewBackward0>), tensor([1.9748], grad_fn=<ViewBackward0>), tensor([1.1838], grad_fn=<ViewBackward0>), tensor([1.5041], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.6269461191242042\n",
      "Batch: 33.0\n",
      "Batch loss: 3.6041245460510254\n",
      "Labels: 132    2.666667\n",
      "133    3.666667\n",
      "134    2.000000\n",
      "135    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.1955], grad_fn=<ViewBackward0>), tensor([1.6086], grad_fn=<ViewBackward0>), tensor([1.7989], grad_fn=<ViewBackward0>), tensor([1.1758], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.5059592307050654\n",
      "Batch: 34.0\n",
      "Batch loss: 4.486798286437988\n",
      "Labels: 136    4.000000\n",
      "137    3.333333\n",
      "138    1.333333\n",
      "139    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.2345], grad_fn=<ViewBackward0>), tensor([1.2476], grad_fn=<ViewBackward0>), tensor([2.0577], grad_fn=<ViewBackward0>), tensor([1.6711], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.7683391169038092\n",
      "Batch: 35.0\n",
      "Batch loss: 2.6581308841705322\n",
      "Labels: 140    3.666667\n",
      "141    1.666667\n",
      "142    3.666667\n",
      "143    1.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.2458], grad_fn=<ViewBackward0>), tensor([1.2893], grad_fn=<ViewBackward0>), tensor([1.5185], grad_fn=<ViewBackward0>), tensor([1.7889], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.3633034115209776\n",
      "Batch: 36.0\n",
      "Batch loss: 1.889474630355835\n",
      "Labels: 144    1.666667\n",
      "145    2.000000\n",
      "146    1.000000\n",
      "147    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.0077], grad_fn=<ViewBackward0>), tensor([1.6665], grad_fn=<ViewBackward0>), tensor([1.2624], grad_fn=<ViewBackward0>), tensor([1.3053], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.26744627687349554\n",
      "Batch: 37.0\n",
      "Batch loss: 2.2476000785827637\n",
      "Labels: 148    2.333333\n",
      "149    3.333333\n",
      "150    1.000000\n",
      "151    3.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.3444], grad_fn=<ViewBackward0>), tensor([1.3643], grad_fn=<ViewBackward0>), tensor([1.2802], grad_fn=<ViewBackward0>), tensor([1.3192], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.7640512223408628\n",
      "Batch: 38.0\n",
      "Batch loss: 3.250415325164795\n",
      "Labels: 152    4.000000\n",
      "153    2.666667\n",
      "154    4.000000\n",
      "155    1.250000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.3591], grad_fn=<ViewBackward0>), tensor([2.0364], grad_fn=<ViewBackward0>), tensor([1.6621], grad_fn=<ViewBackward0>), tensor([1.6551], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.3789618507082508\n",
      "Batch: 39.0\n",
      "Batch loss: 3.2729427814483643\n",
      "Labels: 156    3.333333\n",
      "157    4.000000\n",
      "158    4.000000\n",
      "159    1.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.7171], grad_fn=<ViewBackward0>), tensor([2.1624], grad_fn=<ViewBackward0>), tensor([1.3788], grad_fn=<ViewBackward0>), tensor([2.1483], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.48380874504703464\n",
      "Labels: 0     1.000000\n",
      "1     2.000000\n",
      "2     4.000000\n",
      "3     3.666667\n",
      "4     4.000000\n",
      "5     4.000000\n",
      "6     1.000000\n",
      "7     3.000000\n",
      "8     1.333333\n",
      "9     4.000000\n",
      "10    1.333333\n",
      "11    2.333333\n",
      "12    2.666667\n",
      "13    3.666667\n",
      "14    3.666667\n",
      "15    2.000000\n",
      "16    3.333333\n",
      "17    3.666667\n",
      "18    4.000000\n",
      "19    3.666667\n",
      "20    4.000000\n",
      "21    3.666667\n",
      "22    4.000000\n",
      "23    3.875000\n",
      "24    4.000000\n",
      "25    1.666667\n",
      "26    1.000000\n",
      "27    3.000000\n",
      "28    3.666667\n",
      "29    1.000000\n",
      "30    3.750000\n",
      "31    3.666667\n",
      "32    4.000000\n",
      "33    1.000000\n",
      "34    4.000000\n",
      "35    2.500000\n",
      "36    2.750000\n",
      "37    3.333333\n",
      "38    4.000000\n",
      "39    2.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.5016]), tensor([1.9289]), tensor([1.6204]), tensor([1.6601]), tensor([1.4211]), tensor([1.4768]), tensor([1.4902]), tensor([1.8734]), tensor([2.0121]), tensor([2.1384]), tensor([2.2682]), tensor([1.7319]), tensor([1.4213]), tensor([1.8383]), tensor([1.6924]), tensor([2.1607]), tensor([1.4694]), tensor([1.7418]), tensor([2.2577]), tensor([1.3106]), tensor([1.9340]), tensor([1.2492]), tensor([2.0028]), tensor([1.4587]), tensor([1.4795]), tensor([1.8848]), tensor([1.4723]), tensor([1.2777]), tensor([1.7337]), tensor([2.1395]), tensor([1.9145]), tensor([2.1131]), tensor([1.7906]), tensor([1.3126]), tensor([1.4120]), tensor([1.7809]), tensor([1.4378]), tensor([1.8524]), tensor([1.7640]), tensor([1.6396])]\n",
      "Eval pearson: -0.058248469892913754\n",
      "Saving the model...\n",
      "Epoch: 1\n",
      "Batch: 0.0\n",
      "Batch loss: 2.858628034591675\n",
      "Labels: 0    3.666667\n",
      "1    3.666667\n",
      "2    2.000000\n",
      "3    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.1610], grad_fn=<ViewBackward0>), tensor([1.6740], grad_fn=<ViewBackward0>), tensor([1.2742], grad_fn=<ViewBackward0>), tensor([1.8391], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.8061790557230685\n",
      "Batch: 1.0\n",
      "Batch loss: 3.82975435256958\n",
      "Labels: 4    4.0\n",
      "5    3.0\n",
      "6    4.0\n",
      "7    4.0\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.7236], grad_fn=<ViewBackward0>), tensor([2.1333], grad_fn=<ViewBackward0>), tensor([1.8066], grad_fn=<ViewBackward0>), tensor([1.8611], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.9478232400325329\n",
      "Batch: 2.0\n",
      "Batch loss: 0.32221168279647827\n",
      "Labels: 8     3.000000\n",
      "9     1.000000\n",
      "10    2.333333\n",
      "11    2.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.3720], grad_fn=<ViewBackward0>), tensor([1.9328], grad_fn=<ViewBackward0>), tensor([2.3237], grad_fn=<ViewBackward0>), tensor([2.1780], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.9506998958099897\n",
      "Batch: 3.0\n",
      "Batch loss: 1.2047873735427856\n",
      "Labels: 12    4.000000\n",
      "13    3.333333\n",
      "14    1.000000\n",
      "15    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.0163], grad_fn=<ViewBackward0>), tensor([2.7363], grad_fn=<ViewBackward0>), tensor([1.6249], grad_fn=<ViewBackward0>), tensor([2.2962], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.5983055359314834\n",
      "Batch: 4.0\n",
      "Batch loss: 1.4737292528152466\n",
      "Labels: 16    1.666667\n",
      "17    4.000000\n",
      "18    3.666667\n",
      "19    3.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.1108], grad_fn=<ViewBackward0>), tensor([2.2361], grad_fn=<ViewBackward0>), tensor([2.3031], grad_fn=<ViewBackward0>), tensor([2.1472], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.8322669507009501\n",
      "Batch: 5.0\n",
      "Batch loss: 1.7773023843765259\n",
      "Labels: 20    3.666667\n",
      "21    4.000000\n",
      "22    2.666667\n",
      "23    1.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.2309], grad_fn=<ViewBackward0>), tensor([2.0135], grad_fn=<ViewBackward0>), tensor([1.6540], grad_fn=<ViewBackward0>), tensor([1.6090], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.8356978433917596\n",
      "Batch: 6.0\n",
      "Batch loss: 1.6553031206130981\n",
      "Labels: 24    4.000000\n",
      "25    1.333333\n",
      "26    1.666667\n",
      "27    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.1670], grad_fn=<ViewBackward0>), tensor([2.4473], grad_fn=<ViewBackward0>), tensor([1.7286], grad_fn=<ViewBackward0>), tensor([2.5800], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.3628206818229013\n",
      "Batch: 7.0\n",
      "Batch loss: 1.641190767288208\n",
      "Labels: 28    3.333333\n",
      "29    1.666667\n",
      "30    3.333333\n",
      "31    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.7832], grad_fn=<ViewBackward0>), tensor([2.3309], grad_fn=<ViewBackward0>), tensor([2.1155], grad_fn=<ViewBackward0>), tensor([2.5042], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.0345228112327795\n",
      "Batch: 8.0\n",
      "Batch loss: 3.039947986602783\n",
      "Labels: 32    1.333333\n",
      "33    4.000000\n",
      "34    2.333333\n",
      "35    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.8244], grad_fn=<ViewBackward0>), tensor([1.7591], grad_fn=<ViewBackward0>), tensor([2.3279], grad_fn=<ViewBackward0>), tensor([1.7831], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.9952307044670473\n",
      "Batch: 9.0\n",
      "Batch loss: 1.6716099977493286\n",
      "Labels: 36    3.333333\n",
      "37    2.200000\n",
      "38    4.000000\n",
      "39    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.7352], grad_fn=<ViewBackward0>), tensor([2.4609], grad_fn=<ViewBackward0>), tensor([2.6797], grad_fn=<ViewBackward0>), tensor([1.8746], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.23975365974627874\n",
      "Batch: 10.0\n",
      "Batch loss: 1.4308875799179077\n",
      "Labels: 40    3.333333\n",
      "41    3.666667\n",
      "42    3.333333\n",
      "43    2.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.2869], grad_fn=<ViewBackward0>), tensor([2.2482], grad_fn=<ViewBackward0>), tensor([1.7886], grad_fn=<ViewBackward0>), tensor([2.8132], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.7453389209520662\n",
      "Batch: 11.0\n",
      "Batch loss: 1.2868890762329102\n",
      "Labels: 44    3.333333\n",
      "45    4.000000\n",
      "46    1.000000\n",
      "47    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.4212], grad_fn=<ViewBackward0>), tensor([2.2988], grad_fn=<ViewBackward0>), tensor([1.9130], grad_fn=<ViewBackward0>), tensor([1.9000], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.7572821391586955\n",
      "Batch: 12.0\n",
      "Batch loss: 1.2168110609054565\n",
      "Labels: 48    4.000000\n",
      "49    3.666667\n",
      "50    3.000000\n",
      "51    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([3.2124], grad_fn=<ViewBackward0>), tensor([1.8600], grad_fn=<ViewBackward0>), tensor([3.2877], grad_fn=<ViewBackward0>), tensor([3.0512], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.10983333556053224\n",
      "Batch: 13.0\n",
      "Batch loss: 1.534498691558838\n",
      "Labels: 52    2.333333\n",
      "53    4.000000\n",
      "54    1.666667\n",
      "55    3.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.9253], grad_fn=<ViewBackward0>), tensor([1.9470], grad_fn=<ViewBackward0>), tensor([2.9598], grad_fn=<ViewBackward0>), tensor([3.0424], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.32536359308453944\n",
      "Batch: 14.0\n",
      "Batch loss: 3.6776201725006104\n",
      "Labels: 56    4.000000\n",
      "57    3.666667\n",
      "58    4.000000\n",
      "59    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.8663], grad_fn=<ViewBackward0>), tensor([1.9062], grad_fn=<ViewBackward0>), tensor([2.3433], grad_fn=<ViewBackward0>), tensor([1.9230], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.30843146467580074\n",
      "Batch: 15.0\n",
      "Batch loss: 1.7943878173828125\n",
      "Labels: 60    4.000000\n",
      "61    2.333333\n",
      "62    3.666667\n",
      "63    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.4231], grad_fn=<ViewBackward0>), tensor([2.4378], grad_fn=<ViewBackward0>), tensor([1.9897], grad_fn=<ViewBackward0>), tensor([2.6334], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.024309393782462933\n",
      "Batch: 16.0\n",
      "Batch loss: 2.8308558464050293\n",
      "Labels: 64    4.000000\n",
      "65    4.000000\n",
      "66    3.666667\n",
      "67    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.9890], grad_fn=<ViewBackward0>), tensor([2.5698], grad_fn=<ViewBackward0>), tensor([2.5930], grad_fn=<ViewBackward0>), tensor([1.9798], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.5994467673474503\n",
      "Batch: 17.0\n",
      "Batch loss: 1.675476312637329\n",
      "Labels: 68    2.333333\n",
      "69    1.000000\n",
      "70    1.000000\n",
      "71    1.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.0363], grad_fn=<ViewBackward0>), tensor([2.0347], grad_fn=<ViewBackward0>), tensor([2.6526], grad_fn=<ViewBackward0>), tensor([2.6769], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.57571674542523\n",
      "Batch: 18.0\n",
      "Batch loss: 1.910055160522461\n",
      "Labels: 72    4.000000\n",
      "73    1.000000\n",
      "74    1.333333\n",
      "75    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.5133], grad_fn=<ViewBackward0>), tensor([2.9423], grad_fn=<ViewBackward0>), tensor([2.5444], grad_fn=<ViewBackward0>), tensor([3.1032], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.26486483005559425\n",
      "Batch: 19.0\n",
      "Batch loss: 1.2145862579345703\n",
      "Labels: 76    3.000000\n",
      "77    4.000000\n",
      "78    3.333333\n",
      "79    2.750000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.0792], grad_fn=<ViewBackward0>), tensor([2.4695], grad_fn=<ViewBackward0>), tensor([2.0451], grad_fn=<ViewBackward0>), tensor([2.6588], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.03985440770336667\n",
      "Batch: 20.0\n",
      "Batch loss: 1.576352596282959\n",
      "Labels: 80    3.500000\n",
      "81    4.000000\n",
      "82    3.666667\n",
      "83    2.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.1016], grad_fn=<ViewBackward0>), tensor([2.5379], grad_fn=<ViewBackward0>), tensor([2.5241], grad_fn=<ViewBackward0>), tensor([2.9522], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.6838210617129743\n",
      "Batch: 21.0\n",
      "Batch loss: 2.3981785774230957\n",
      "Labels: 84    3.666667\n",
      "85    1.000000\n",
      "86    3.333333\n",
      "87    1.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.9821], grad_fn=<ViewBackward0>), tensor([2.1172], grad_fn=<ViewBackward0>), tensor([2.0961], grad_fn=<ViewBackward0>), tensor([3.5190], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.18164266802627804\n",
      "Batch: 22.0\n",
      "Batch loss: 2.1776533126831055\n",
      "Labels: 88    4.000000\n",
      "89    1.333333\n",
      "90    4.000000\n",
      "91    2.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.4862], grad_fn=<ViewBackward0>), tensor([3.2347], grad_fn=<ViewBackward0>), tensor([2.6310], grad_fn=<ViewBackward0>), tensor([2.9642], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.9747352663419939\n",
      "Batch: 23.0\n",
      "Batch loss: 1.2441737651824951\n",
      "Labels: 92    1.333333\n",
      "93    1.333333\n",
      "94    4.000000\n",
      "95    3.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.3483], grad_fn=<ViewBackward0>), tensor([1.9941], grad_fn=<ViewBackward0>), tensor([3.1346], grad_fn=<ViewBackward0>), tensor([2.0050], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.5089074553824023\n",
      "Batch: 24.0\n",
      "Batch loss: 1.4064141511917114\n",
      "Labels: 96    1.333333\n",
      "97    4.000000\n",
      "98    2.500000\n",
      "99    1.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.7837], grad_fn=<ViewBackward0>), tensor([2.4383], grad_fn=<ViewBackward0>), tensor([1.9048], grad_fn=<ViewBackward0>), tensor([1.8538], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.136949585446628\n",
      "Batch: 25.0\n",
      "Batch loss: 1.404052495956421\n",
      "Labels: 100    1.400000\n",
      "101    3.000000\n",
      "102    4.000000\n",
      "103    1.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.1514], grad_fn=<ViewBackward0>), tensor([2.3983], grad_fn=<ViewBackward0>), tensor([1.8895], grad_fn=<ViewBackward0>), tensor([1.8187], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.09288825386271411\n",
      "Batch: 26.0\n",
      "Batch loss: 1.2192567586898804\n",
      "Labels: 104    4.000000\n",
      "105    4.000000\n",
      "106    3.000000\n",
      "107    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.6427], grad_fn=<ViewBackward0>), tensor([2.5482], grad_fn=<ViewBackward0>), tensor([2.1680], grad_fn=<ViewBackward0>), tensor([2.1821], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.9631619070514379\n",
      "Batch: 27.0\n",
      "Batch loss: 3.0169782638549805\n",
      "Labels: 108    3.333333\n",
      "109    4.000000\n",
      "110    4.000000\n",
      "111    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.7880], grad_fn=<ViewBackward0>), tensor([2.1858], grad_fn=<ViewBackward0>), tensor([2.1580], grad_fn=<ViewBackward0>), tensor([2.2693], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.9751794813449361\n",
      "Batch: 28.0\n",
      "Batch loss: 1.616858959197998\n",
      "Labels: 112    4.000000\n",
      "113    4.000000\n",
      "114    1.333333\n",
      "115    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([3.3748], grad_fn=<ViewBackward0>), tensor([2.0819], grad_fn=<ViewBackward0>), tensor([2.7375], grad_fn=<ViewBackward0>), tensor([3.3475], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.16138605150719135\n",
      "Batch: 29.0\n",
      "Batch loss: 2.244340419769287\n",
      "Labels: 116    4.000000\n",
      "117    4.000000\n",
      "118    3.666667\n",
      "119    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.1761], grad_fn=<ViewBackward0>), tensor([2.6781], grad_fn=<ViewBackward0>), tensor([2.9055], grad_fn=<ViewBackward0>), tensor([2.1768], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.7649909477222393\n",
      "Batch: 30.0\n",
      "Batch loss: 1.6144574880599976\n",
      "Labels: 120    2.000000\n",
      "121    1.666667\n",
      "122    2.333333\n",
      "123    3.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([3.0737], grad_fn=<ViewBackward0>), tensor([3.7840], grad_fn=<ViewBackward0>), tensor([2.1941], grad_fn=<ViewBackward0>), tensor([2.7708], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.4814457035322229\n",
      "Batch: 31.0\n",
      "Batch loss: 0.8074134588241577\n",
      "Labels: 124    3.000000\n",
      "125    1.000000\n",
      "126    3.333333\n",
      "127    3.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.1843], grad_fn=<ViewBackward0>), tensor([2.4690], grad_fn=<ViewBackward0>), tensor([3.3849], grad_fn=<ViewBackward0>), tensor([3.0314], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.5027229867177049\n",
      "Batch: 32.0\n",
      "Batch loss: 1.2720881700515747\n",
      "Labels: 128    2.333333\n",
      "129    2.000000\n",
      "130    3.333333\n",
      "131    3.500000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.3226], grad_fn=<ViewBackward0>), tensor([3.2192], grad_fn=<ViewBackward0>), tensor([1.8232], grad_fn=<ViewBackward0>), tensor([2.3505], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.7485846387845454\n",
      "Batch: 33.0\n",
      "Batch loss: 3.052003860473633\n",
      "Labels: 132    2.666667\n",
      "133    3.666667\n",
      "134    2.000000\n",
      "135    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.1198], grad_fn=<ViewBackward0>), tensor([2.1506], grad_fn=<ViewBackward0>), tensor([2.6372], grad_fn=<ViewBackward0>), tensor([1.3334], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.4343036636858385\n",
      "Batch: 34.0\n",
      "Batch loss: 3.7610199451446533\n",
      "Labels: 136    4.000000\n",
      "137    3.333333\n",
      "138    1.333333\n",
      "139    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.4591], grad_fn=<ViewBackward0>), tensor([1.3440], grad_fn=<ViewBackward0>), tensor([2.4982], grad_fn=<ViewBackward0>), tensor([2.1907], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.6193001276415325\n",
      "Batch: 35.0\n",
      "Batch loss: 2.29618239402771\n",
      "Labels: 140    3.666667\n",
      "141    1.666667\n",
      "142    3.666667\n",
      "143    1.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.4403], grad_fn=<ViewBackward0>), tensor([1.4724], grad_fn=<ViewBackward0>), tensor([1.7043], grad_fn=<ViewBackward0>), tensor([2.2493], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.4453156518456998\n",
      "Batch: 36.0\n",
      "Batch loss: 1.7930394411087036\n",
      "Labels: 144    1.666667\n",
      "145    2.000000\n",
      "146    1.000000\n",
      "147    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.5557], grad_fn=<ViewBackward0>), tensor([2.1698], grad_fn=<ViewBackward0>), tensor([1.2247], grad_fn=<ViewBackward0>), tensor([1.4895], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.1425489451152306\n",
      "Batch: 37.0\n",
      "Batch loss: 1.241900086402893\n",
      "Labels: 148    2.333333\n",
      "149    3.333333\n",
      "150    1.000000\n",
      "151    3.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.9826], grad_fn=<ViewBackward0>), tensor([1.8484], grad_fn=<ViewBackward0>), tensor([1.7373], grad_fn=<ViewBackward0>), tensor([1.8856], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.5214793596219351\n",
      "Batch: 38.0\n",
      "Batch loss: 2.115443229675293\n",
      "Labels: 152    4.000000\n",
      "153    2.666667\n",
      "154    4.000000\n",
      "155    1.250000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.0399], grad_fn=<ViewBackward0>), tensor([2.9806], grad_fn=<ViewBackward0>), tensor([2.0996], grad_fn=<ViewBackward0>), tensor([2.2039], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.299176060438841\n",
      "Batch: 39.0\n",
      "Batch loss: 1.7929900884628296\n",
      "Labels: 156    3.333333\n",
      "157    4.000000\n",
      "158    4.000000\n",
      "159    1.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.5571], grad_fn=<ViewBackward0>), tensor([2.9982], grad_fn=<ViewBackward0>), tensor([2.2399], grad_fn=<ViewBackward0>), tensor([3.2376], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.668247395564265\n",
      "Labels: 0     1.000000\n",
      "1     2.000000\n",
      "2     4.000000\n",
      "3     3.666667\n",
      "4     4.000000\n",
      "5     4.000000\n",
      "6     1.000000\n",
      "7     3.000000\n",
      "8     1.333333\n",
      "9     4.000000\n",
      "10    1.333333\n",
      "11    2.333333\n",
      "12    2.666667\n",
      "13    3.666667\n",
      "14    3.666667\n",
      "15    2.000000\n",
      "16    3.333333\n",
      "17    3.666667\n",
      "18    4.000000\n",
      "19    3.666667\n",
      "20    4.000000\n",
      "21    3.666667\n",
      "22    4.000000\n",
      "23    3.875000\n",
      "24    4.000000\n",
      "25    1.666667\n",
      "26    1.000000\n",
      "27    3.000000\n",
      "28    3.666667\n",
      "29    1.000000\n",
      "30    3.750000\n",
      "31    3.666667\n",
      "32    4.000000\n",
      "33    1.000000\n",
      "34    4.000000\n",
      "35    2.500000\n",
      "36    2.750000\n",
      "37    3.333333\n",
      "38    4.000000\n",
      "39    2.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.2654]), tensor([3.1086]), tensor([2.6004]), tensor([2.7044]), tensor([2.2988]), tensor([2.3053]), tensor([2.2502]), tensor([3.1096]), tensor([3.1450]), tensor([3.3523]), tensor([3.4993]), tensor([2.6691]), tensor([2.2931]), tensor([2.8227]), tensor([2.7911]), tensor([3.4882]), tensor([2.3085]), tensor([2.6729]), tensor([3.4334]), tensor([2.2482]), tensor([3.0128]), tensor([2.1968]), tensor([3.1840]), tensor([2.2761]), tensor([2.2980]), tensor([3.0610]), tensor([2.2647]), tensor([2.1230]), tensor([2.7765]), tensor([3.3264]), tensor([2.9985]), tensor([3.3726]), tensor([2.7510]), tensor([2.2120]), tensor([2.2443]), tensor([2.7828]), tensor([2.3104]), tensor([2.9375]), tensor([2.8203]), tensor([2.7722])]\n",
      "Eval pearson: -0.04529455667878812\n",
      "Saving the model...\n",
      "Epoch: 2\n",
      "Batch: 0.0\n",
      "Batch loss: 0.44962984323501587\n",
      "Labels: 0    3.666667\n",
      "1    3.666667\n",
      "2    2.000000\n",
      "3    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([3.4239], grad_fn=<ViewBackward0>), tensor([2.8164], grad_fn=<ViewBackward0>), tensor([2.2097], grad_fn=<ViewBackward0>), tensor([3.0137], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.8351572962512044\n",
      "Batch: 1.0\n",
      "Batch loss: 1.265502691268921\n",
      "Labels: 4    4.0\n",
      "5    3.0\n",
      "6    4.0\n",
      "7    4.0\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.6668], grad_fn=<ViewBackward0>), tensor([3.0806], grad_fn=<ViewBackward0>), tensor([2.7135], grad_fn=<ViewBackward0>), tensor([2.7261], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.9910455079944208\n",
      "Batch: 2.0\n",
      "Batch loss: 0.9770115613937378\n",
      "Labels: 8     3.000000\n",
      "9     1.000000\n",
      "10    2.333333\n",
      "11    2.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([3.1654], grad_fn=<ViewBackward0>), tensor([2.5540], grad_fn=<ViewBackward0>), tensor([3.3921], grad_fn=<ViewBackward0>), tensor([2.9206], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.7867645412965976\n",
      "Batch: 3.0\n",
      "Batch loss: 0.8505586981773376\n",
      "Labels: 12    4.000000\n",
      "13    3.333333\n",
      "14    1.000000\n",
      "15    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.3067], grad_fn=<ViewBackward0>), tensor([3.2989], grad_fn=<ViewBackward0>), tensor([1.7304], grad_fn=<ViewBackward0>), tensor([2.6806], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.6119521216035414\n",
      "Batch: 4.0\n",
      "Batch loss: 1.0443053245544434\n",
      "Labels: 16    1.666667\n",
      "17    4.000000\n",
      "18    3.666667\n",
      "19    3.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.3549], grad_fn=<ViewBackward0>), tensor([2.5850], grad_fn=<ViewBackward0>), tensor([2.5991], grad_fn=<ViewBackward0>), tensor([2.2506], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.6781263686620926\n",
      "Batch: 5.0\n",
      "Batch loss: 1.5533413887023926\n",
      "Labels: 20    3.666667\n",
      "21    4.000000\n",
      "22    2.666667\n",
      "23    1.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.4221], grad_fn=<ViewBackward0>), tensor([2.1700], grad_fn=<ViewBackward0>), tensor([1.5891], grad_fn=<ViewBackward0>), tensor([1.7261], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.7461113002514617\n",
      "Batch: 6.0\n",
      "Batch loss: 1.47844660282135\n",
      "Labels: 24    4.000000\n",
      "25    1.333333\n",
      "26    1.666667\n",
      "27    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.3206], grad_fn=<ViewBackward0>), tensor([2.5738], grad_fn=<ViewBackward0>), tensor([1.6988], grad_fn=<ViewBackward0>), tensor([2.7536], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.42712527581013365\n",
      "Batch: 7.0\n",
      "Batch loss: 1.4744952917099\n",
      "Labels: 28    3.333333\n",
      "29    1.666667\n",
      "30    3.333333\n",
      "31    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.7628], grad_fn=<ViewBackward0>), tensor([2.5201], grad_fn=<ViewBackward0>), tensor([2.3274], grad_fn=<ViewBackward0>), tensor([2.6995], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.060250259940333395\n",
      "Batch: 8.0\n",
      "Batch loss: 2.948795795440674\n",
      "Labels: 32    1.333333\n",
      "33    4.000000\n",
      "34    2.333333\n",
      "35    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([3.0843], grad_fn=<ViewBackward0>), tensor([1.9463], grad_fn=<ViewBackward0>), tensor([2.4641], grad_fn=<ViewBackward0>), tensor([1.8800], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.9867497229449376\n",
      "Batch: 9.0\n",
      "Batch loss: 1.1640698909759521\n",
      "Labels: 36    3.333333\n",
      "37    2.200000\n",
      "38    4.000000\n",
      "39    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([3.1066], grad_fn=<ViewBackward0>), tensor([2.9966], grad_fn=<ViewBackward0>), tensor([3.2462], grad_fn=<ViewBackward0>), tensor([2.1555], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.29584446403689146\n",
      "Batch: 10.0\n",
      "Batch loss: 0.9121596217155457\n",
      "Labels: 40    3.333333\n",
      "41    3.666667\n",
      "42    3.333333\n",
      "43    2.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.6754], grad_fn=<ViewBackward0>), tensor([2.7527], grad_fn=<ViewBackward0>), tensor([2.1170], grad_fn=<ViewBackward0>), tensor([3.2826], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.6783638514805836\n",
      "Batch: 11.0\n",
      "Batch loss: 0.8203516006469727\n",
      "Labels: 44    3.333333\n",
      "45    4.000000\n",
      "46    1.000000\n",
      "47    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([3.0697], grad_fn=<ViewBackward0>), tensor([2.8455], grad_fn=<ViewBackward0>), tensor([2.3168], grad_fn=<ViewBackward0>), tensor([2.2859], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.7320103571281344\n",
      "Batch: 12.0\n",
      "Batch loss: 0.7140310406684875\n",
      "Labels: 48    4.000000\n",
      "49    3.666667\n",
      "50    3.000000\n",
      "51    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([3.7709], grad_fn=<ViewBackward0>), tensor([2.2604], grad_fn=<ViewBackward0>), tensor([3.8248], grad_fn=<ViewBackward0>), tensor([3.6183], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.08248780466933632\n",
      "Batch: 13.0\n",
      "Batch loss: 1.4901175498962402\n",
      "Labels: 52    2.333333\n",
      "53    4.000000\n",
      "54    1.666667\n",
      "55    3.333333\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.2574], grad_fn=<ViewBackward0>), tensor([2.2709], grad_fn=<ViewBackward0>), tensor([3.3877], grad_fn=<ViewBackward0>), tensor([3.3871], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.3660200524686853\n",
      "Batch: 14.0\n",
      "Batch loss: 2.644920825958252\n",
      "Labels: 56    4.000000\n",
      "57    3.666667\n",
      "58    4.000000\n",
      "59    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.2681], grad_fn=<ViewBackward0>), tensor([2.1975], grad_fn=<ViewBackward0>), tensor([2.5446], grad_fn=<ViewBackward0>), tensor([2.1825], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.3983890275884329\n",
      "Batch: 15.0\n",
      "Batch loss: 1.2521536350250244\n",
      "Labels: 60    4.000000\n",
      "61    2.333333\n",
      "62    3.666667\n",
      "63    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.7456], grad_fn=<ViewBackward0>), tensor([2.7668], grad_fn=<ViewBackward0>), tensor([2.1888], grad_fn=<ViewBackward0>), tensor([2.9689], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.007360829683759455\n",
      "Batch: 16.0\n",
      "Batch loss: 2.0894622802734375\n",
      "Labels: 64    4.000000\n",
      "65    4.000000\n",
      "66    3.666667\n",
      "67    4.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.2793], grad_fn=<ViewBackward0>), tensor([2.7959], grad_fn=<ViewBackward0>), tensor([2.7882], grad_fn=<ViewBackward0>), tensor([2.2180], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.567346279535661\n",
      "Batch: 17.0\n",
      "Batch loss: 2.3488240242004395\n",
      "Labels: 68    2.333333\n",
      "69    1.000000\n",
      "70    1.000000\n",
      "71    1.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.2790], grad_fn=<ViewBackward0>), tensor([2.3670], grad_fn=<ViewBackward0>), tensor([3.0412], grad_fn=<ViewBackward0>), tensor([2.8322], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.6387274011283759\n",
      "Batch: 18.0\n",
      "Batch loss: 1.8908287286758423\n",
      "Labels: 72    4.000000\n",
      "73    1.000000\n",
      "74    1.333333\n",
      "75    2.666667\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.7179], grad_fn=<ViewBackward0>), tensor([2.8529], grad_fn=<ViewBackward0>), tensor([2.8189], grad_fn=<ViewBackward0>), tensor([3.1950], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.0734261792116027\n",
      "Batch: 19.0\n",
      "Batch loss: 1.6240696907043457\n",
      "Labels: 76    3.000000\n",
      "77    4.000000\n",
      "78    3.333333\n",
      "79    2.750000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.7700], grad_fn=<ViewBackward0>), tensor([2.6749], grad_fn=<ViewBackward0>), tensor([1.5369], grad_fn=<ViewBackward0>), tensor([2.7366], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: 0.14179292835080648\n",
      "Batch: 20.0\n",
      "Batch loss: 2.5005857944488525\n",
      "Labels: 80    3.500000\n",
      "81    4.000000\n",
      "82    3.666667\n",
      "83    2.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([1.7982], grad_fn=<ViewBackward0>), tensor([2.0033], grad_fn=<ViewBackward0>), tensor([1.9250], grad_fn=<ViewBackward0>), tensor([2.2932], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.8003728366363244\n",
      "Batch: 21.0\n",
      "Batch loss: 2.7810862064361572\n",
      "Labels: 84    3.666667\n",
      "85    1.000000\n",
      "86    3.333333\n",
      "87    1.000000\n",
      "Name: overall, dtype: float64\n",
      "Predictions: [tensor([2.3694], grad_fn=<ViewBackward0>), tensor([1.6043], grad_fn=<ViewBackward0>), tensor([1.2136], grad_fn=<ViewBackward0>), tensor([3.1408], grad_fn=<ViewBackward0>)]\n",
      "Batch pearson: -0.3393605527846659\n",
      "Batch: 22.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m lstmonxlmroberta \u001b[38;5;241m=\u001b[39m LSTMOnXLMRoberta(\u001b[38;5;241m768\u001b[39m, \u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlstmonxlmroberta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 158\u001b[0m, in \u001b[0;36mLSTMOnXLMRoberta.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m input_ids_val, labels_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_data(val_df)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameter_to_optimize()\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 122\u001b[0m, in \u001b[0;36mLSTMOnXLMRoberta.train_model\u001b[0;34m(self, input_ids_train, labels_train, input_ids_val, labels_val, batch_size)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear gradients\u001b[39;00m\n\u001b[1;32m    121\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_batch\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    123\u001b[0m     index1, index2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(row[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(row[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    124\u001b[0m     row_padded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_to_same_size(row) \n",
      "File \u001b[0;32m~/anaconda3/envs/project/lib/python3.12/site-packages/pandas/core/base.py:836\u001b[0m, in \u001b[0;36mIndexOpsMixin.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    834\u001b[0m to_list \u001b[38;5;241m=\u001b[39m tolist\n\u001b[0;32m--> 836\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator:\n\u001b[1;32m    837\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03m    Return an iterator of the values.\u001b[39;00m\n\u001b[1;32m    839\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;66;03m# We are explicitly making element iterators.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstmonxlmroberta = LSTMOnXLMRoberta(768, 384, 1)\n",
    "lstmonxlmroberta.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
